{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#라이브러리 임포트\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, optimizers\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#이미지 사이즈 조절용 함수\n",
    "def read_and_preprocess(img_path):\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_COLOR) # reading the image\n",
    "    img = cv2.resize(img, (256, 256)) # resizing it (I just like it to be powers of 2)\n",
    "    img = np.array(img, dtype='float32') # convert its datatype so that it could be normalized\n",
    "    img = img/255 # normalization (now every pixel is in the range of 0 and 1)\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#이미지 및 레이블 관리\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "train_path = \"./train/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#이미지와 레이블 불러오기\n",
    "for folder in os.scandir(train_path):\n",
    "    for entry in os.scandir(train_path + folder.name):\n",
    "\n",
    "        X_train.append(read_and_preprocess(train_path + folder.name + '/' + entry.name))\n",
    "        \n",
    "        if folder.name[0]=='C':\n",
    "            y_train.append(0)\n",
    "        elif folder.name[0]=='V':\n",
    "            y_train.append(1)\n",
    "        else:\n",
    "            y_train.append(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(251, 256, 256, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X_train내용 확인\n",
    "X_train = np.array(X_train)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(251,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#y_train내용 확인\n",
    "y_train = np.array(y_train)\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 3 artists>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#레이블별 데이터 갯수 시각화\n",
    "covid_count = len(y_train[y_train==0])\n",
    "pneumonia_count = len(y_train[y_train==1])\n",
    "normal_count = len(y_train[y_train==2])\n",
    "\n",
    "plt.title(\"Train Images for Each Label\")\n",
    "plt.bar([\"Covid\", \"Viral Pneumonia\", \"Normal\"],[covid_count, pneumonia_count, normal_count])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 증대를 위해 영상 좌우반전\n",
    "X_aug = []\n",
    "y_aug = []\n",
    "\n",
    "for i in range(0, len(y_train)):\n",
    "    X_new = np.fliplr(X_train[i])\n",
    "    X_aug.append(X_new)\n",
    "    y_aug.append(y_train[i])\n",
    "\n",
    "X_aug = np.array(X_aug)\n",
    "y_aug = np.array(y_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(502, 256, 256, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#증배된 데이터 확인\n",
    "X_train = np.append(X_train, X_aug, axis=0)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(502,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = np.append(y_train, y_aug, axis=0)\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#검증 이미지 불러오기\n",
    "X_val = []\n",
    "y_val = []\n",
    "\n",
    "val_path = './test/'\n",
    "\n",
    "for folder in os.scandir(val_path):\n",
    "    for entry in os.scandir(val_path + folder.name):\n",
    "\n",
    "        X_val.append(read_and_preprocess(val_path + folder.name + '/' + entry.name))\n",
    "        \n",
    "        if folder.name[0]=='C':\n",
    "            y_val.append(0)\n",
    "        elif folder.name[0]=='V':\n",
    "            y_val.append(1)\n",
    "        else:\n",
    "            y_val.append(2)\n",
    "            \n",
    "X_val = np.array(X_val)\n",
    "y_val = np.array(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66, 256, 256, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 3 artists>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "covid_count = len(y_val[y_val==0])\n",
    "pneumonia_count = len(y_val[y_val==1])\n",
    "normal_count = len(y_val[y_val==2])\n",
    "\n",
    "plt.title(\"Validation Images for Each Label\")\n",
    "plt.bar([\"Covid\", \"Viral Pneumonia\", \"Normal\"],[covid_count, pneumonia_count, normal_count])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 5s 0us/step\n"
     ]
    }
   ],
   "source": [
    "#전이학습을 위한 모델 생성\n",
    "basemodel = VGG16(weights = 'imagenet', include_top = False, input_tensor = Input(shape=(256, 256, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 256, 256, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 256, 256, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 256, 256, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 128, 128, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 128, 128, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 64, 64, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 32, 32, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#모델 레이어 확인\n",
    "basemodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#베이스모델 가중치 변경 금지\n",
    "for layer in basemodel.layers:\n",
    "  layers.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#베이스모델 뒤에 추가레이어 쌓기\n",
    "headmodel = basemodel.output\n",
    "headmodel = Flatten(name= 'flatten')(headmodel)\n",
    "headmodel = Dense(3, activation = 'softmax')(headmodel)\n",
    "\n",
    "model = Model(inputs = basemodel.input, outputs = headmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 256, 256, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 256, 256, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 256, 256, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 128, 128, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 128, 128, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 64, 64, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 32, 32, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 3)                 98307     \n",
      "=================================================================\n",
      "Total params: 14,812,995\n",
      "Trainable params: 14,812,995\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#쌓은모델 레이어 확인\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#옵티마이저 선언\n",
    "opt = optimizers.Adam(learning_rate=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 컴파일\n",
    "model.compile(loss = 'sparse_categorical_crossentropy', optimizer=opt, metrics= [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#조기종료 설정\n",
    "earlystopping = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 자동저장 설정\n",
    "checkpointer = ModelCheckpoint(filepath=\"covid_classifier_weights.h5\", verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " 7/32 [=====>........................] - ETA: 4:50 - loss: 0.8512 - accuracy: 0.6250"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-d2c72c5a12ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#모댈 학습 시작\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearlystopping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpointer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3021\u001b[0m       (graph_function,\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3023\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1960\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#모댈 학습 시작\n",
    "history = model.fit(X_train, y_train, epochs = 100, validation_data=(X_val, y_val), batch_size=16, shuffle=True, callbacks=[earlystopping, checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#학습곡선 시각화\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델구성 json으로 저장\n",
    "model_json = model.to_json()\n",
    "with open(\"covid_classifier_model.json\",\"w\") as json_file:\n",
    "  json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'covid_classifier_model.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-646351f703a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#저장한 모델 평가를 위한 모델 불러오기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'covid_classifier_model.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mjson_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mjson_savedModel\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mjson_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_from_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_savedModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'covid_classifier_model.json'"
     ]
    }
   ],
   "source": [
    "#저장한 모델 평가를 위한 모델 불러오기\n",
    "with open('covid_classifier_model.json', 'r') as json_file:\n",
    "    json_savedModel= json_file.read()\n",
    "\n",
    "model = tf.keras.models.model_from_json(json_savedModel)\n",
    "model.load_weights('covid_classifier_weights.h5')\n",
    "model.compile(loss = 'sparse_categorical_crossentropy', optimizer=opt, metrics= [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-cde1bc0239e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1725\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1726\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1727\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1728\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1729\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    922\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3021\u001b[0m       (graph_function,\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3023\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1960\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모댈 예측 시작\n",
    "predict = []\n",
    "\n",
    "for i in predictions:\n",
    "  predict.append(np.argmax(i))\n",
    "\n",
    "predict = np.asarray(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 정확도 확인\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_val, predict)\n",
    "accuracy\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(y_val, predict)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#혼동행렬 확인\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_val, predict)\n",
    "plt.figure(figsize = (7,7))\n",
    "sns.heatmap(cm, annot=True, cmap='Blues')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ba6c0b500b337a3ffd66c9b67313e4affd215fbda1074d02b914b9718c5d291e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
